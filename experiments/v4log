Last login: Wed Dec  4 12:29:45 on ttys000
(base) Evangelie-2:~ evangelie$ source activate tensorflow
(tensorflow) Evangelie-2:~ evangelie$ cd ~/Documents/GitHub/panotti/
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
['/Users/evangelie/Documents/GitHub/panotti', '/miniconda3/envs/tensorflow/lib/python37.zip', '/miniconda3/envs/tensorflow/lib/python3.7', '/miniconda3/envs/tensorflow/lib/python3.7/lib-dynload', '/Users/evangelie/.local/lib/python3.7/site-packages', '/miniconda3/envs/tensorflow/lib/python3.7/site-packages']
3.7.5 (default, Oct 25 2019, 10:52:18) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
Using TensorFlow backend.
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2112
total files =  2126 , going to load total_load =  2112
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1034_TIE_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1022_IEO_ANG_HI. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1065_IEO_ANG_MD. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1086_DFA_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1084_IWL_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1056_IEO_DIS_HI.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1048_ITS_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1047_MTI_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1033_MTI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1006_IEO_DIS_LO.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1054_IOM_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1027_TAI_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1040_DFA_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1017_IEO_FEA_HI. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1088_IWL_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1020_IWW_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1086_TIE_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1066_IWL_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1076_TSI_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1071_TAI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1036_ITH_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1078_TIE_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1062_WSI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1006_ITS_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1064_IWL_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1018_TIE_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1015_IOM_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1020_ITH_SAD_XX. Loading class 6/6: 'SAD', File 301/373: Preprocessed/Train/SAD/1022_ITS_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2112, 96, 420, 1) , channels =  1
2019-12-04 20:16:15.151426: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-04 20:16:15.152339: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_1 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_2 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_3 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_4 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_5 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Train on 2112 samples, validate on 2112 samples
Epoch 1/40
2112/2112 [==============================] - 267s 127ms/step - loss: 3.0596 - accuracy: 0.2623 - val_loss: 2.9767 - val_accuracy: 0.1799

Epoch 00001: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 2/40
2112/2112 [==============================] - 244s 115ms/step - loss: 1.8274 - accuracy: 0.3073 - val_loss: 2.1860 - val_accuracy: 0.2320

Epoch 00002: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 3/40
2112/2112 [==============================] - 243s 115ms/step - loss: 1.7529 - accuracy: 0.3267 - val_loss: 2.7376 - val_accuracy: 0.2595

Epoch 00003: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 4/40
2112/2112 [==============================] - 242s 115ms/step - loss: 1.6983 - accuracy: 0.3385 - val_loss: 1.6594 - val_accuracy: 0.2945

Epoch 00004: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 5/40
2112/2112 [==============================] - 242s 114ms/step - loss: 1.6611 - accuracy: 0.3542 - val_loss: 1.4763 - val_accuracy: 0.4195

Epoch 00005: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 6/40
2112/2112 [==============================] - 244s 116ms/step - loss: 1.6334 - accuracy: 0.3679 - val_loss: 1.4757 - val_accuracy: 0.3902

Epoch 00006: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 7/40
2112/2112 [==============================] - 244s 116ms/step - loss: 1.6179 - accuracy: 0.3589 - val_loss: 1.4630 - val_accuracy: 0.4228

Epoch 00007: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 8/40
2112/2112 [==============================] - 242s 114ms/step - loss: 1.6179 - accuracy: 0.3613 - val_loss: 1.4739 - val_accuracy: 0.4115

Epoch 00008: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 9/40
2112/2112 [==============================] - 244s 116ms/step - loss: 1.5889 - accuracy: 0.3707 - val_loss: 1.4637 - val_accuracy: 0.4209

Epoch 00009: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 10/40
2112/2112 [==============================] - 243s 115ms/step - loss: 1.5665 - accuracy: 0.3797 - val_loss: 1.3467 - val_accuracy: 0.4688

Epoch 00010: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 11/40
2112/2112 [==============================] - 249s 118ms/step - loss: 1.5511 - accuracy: 0.3878 - val_loss: 1.4095 - val_accuracy: 0.4455

Epoch 00011: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 12/40
2112/2112 [==============================] - 242s 115ms/step - loss: 1.5013 - accuracy: 0.4143 - val_loss: 1.4911 - val_accuracy: 0.4062

Epoch 00012: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 13/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.5102 - accuracy: 0.3968 - val_loss: 1.2799 - val_accuracy: 0.5000

Epoch 00013: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 14/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4843 - accuracy: 0.4143 - val_loss: 1.2941 - val_accuracy: 0.4844

Epoch 00014: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 15/40
2112/2112 [==============================] - 244s 115ms/step - loss: 1.4427 - accuracy: 0.4209 - val_loss: 1.3108 - val_accuracy: 0.4953

Epoch 00015: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 16/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4233 - accuracy: 0.4361 - val_loss: 1.2651 - val_accuracy: 0.4834

Epoch 00016: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 17/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4145 - accuracy: 0.4323 - val_loss: 1.1947 - val_accuracy: 0.5365

Epoch 00017: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 18/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3811 - accuracy: 0.4635 - val_loss: 1.2536 - val_accuracy: 0.5298

Epoch 00018: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 19/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4031 - accuracy: 0.4479 - val_loss: 1.2232 - val_accuracy: 0.5251

Epoch 00019: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 20/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4017 - accuracy: 0.4399 - val_loss: 1.1913 - val_accuracy: 0.5365

Epoch 00020: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 21/40
2112/2112 [==============================] - 244s 115ms/step - loss: 1.3737 - accuracy: 0.4560 - val_loss: 1.2294 - val_accuracy: 0.5213

Epoch 00021: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 22/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3161 - accuracy: 0.4858 - val_loss: 1.2632 - val_accuracy: 0.4853

Epoch 00022: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 23/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3156 - accuracy: 0.4730 - val_loss: 1.2936 - val_accuracy: 0.4688

Epoch 00023: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 24/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2949 - accuracy: 0.4910 - val_loss: 1.1643 - val_accuracy: 0.5445

Epoch 00024: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 25/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2957 - accuracy: 0.4749 - val_loss: 1.1268 - val_accuracy: 0.5634

Epoch 00025: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 26/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2684 - accuracy: 0.5024 - val_loss: 1.0976 - val_accuracy: 0.5677

Epoch 00026: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 27/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2620 - accuracy: 0.5156 - val_loss: 1.1850 - val_accuracy: 0.5440

Epoch 00027: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 28/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2519 - accuracy: 0.5275 - val_loss: 1.1529 - val_accuracy: 0.5516

Epoch 00028: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 29/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2202 - accuracy: 0.5180 - val_loss: 1.0907 - val_accuracy: 0.5734

Epoch 00029: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 30/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2419 - accuracy: 0.5090 - val_loss: 1.0748 - val_accuracy: 0.5758

Epoch 00030: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 31/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2160 - accuracy: 0.5232 - val_loss: 1.0730 - val_accuracy: 0.5786

Epoch 00031: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 32/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2304 - accuracy: 0.5109 - val_loss: 1.0068 - val_accuracy: 0.6146

Epoch 00032: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 33/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1999 - accuracy: 0.5265 - val_loss: 1.0786 - val_accuracy: 0.5866

Epoch 00033: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 34/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1742 - accuracy: 0.5298 - val_loss: 1.0237 - val_accuracy: 0.6094

Epoch 00034: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 35/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1655 - accuracy: 0.5374 - val_loss: 0.9951 - val_accuracy: 0.6231

Epoch 00035: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 36/40
2112/2112 [==============================] - 244s 115ms/step - loss: 1.1499 - accuracy: 0.5502 - val_loss: 0.9874 - val_accuracy: 0.6027

Epoch 00036: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 37/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1585 - accuracy: 0.5270 - val_loss: 0.9308 - val_accuracy: 0.6529

Epoch 00037: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 38/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1210 - accuracy: 0.5691 - val_loss: 0.9316 - val_accuracy: 0.6491

Epoch 00038: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 39/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1148 - accuracy: 0.5568 - val_loss: 0.9939 - val_accuracy: 0.6335

Epoch 00039: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
Epoch 40/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1255 - accuracy: 0.5436 - val_loss: 0.8986 - val_accuracy: 0.6553

Epoch 00040: saving model to 4_convdropout0.5densedropout0.4weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1062_TIE_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1037_MTI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1076_TIE_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1008_ITS_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1083_IWL_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1090_ITH_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.3923982354931366
Dev set accuracy: 0.4887218177318573
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2112
total files =  2126 , going to load total_load =  2112
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1022_TSI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1038_TAI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1038_TSI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1088_ITH_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1044_IOM_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 301/373: Preprocessed/Train/SAD/1004_WSI_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2112, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_6 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_7 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_8 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_9 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_10 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Train on 2112 samples, validate on 2112 samples
Epoch 1/40
2112/2112 [==============================] - 245s 116ms/step - loss: 2.9450 - accuracy: 0.2694 - val_loss: 2.0788 - val_accuracy: 0.2112

Epoch 00001: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 2/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.6885 - accuracy: 0.3277 - val_loss: 1.9240 - val_accuracy: 0.2377

Epoch 00002: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 3/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.6606 - accuracy: 0.3305 - val_loss: 1.5974 - val_accuracy: 0.3920

Epoch 00003: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 4/40
2112/2112 [==============================] - 240s 114ms/step - loss: 1.6103 - accuracy: 0.3523 - val_loss: 1.7269 - val_accuracy: 0.2926

Epoch 00004: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 5/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.5920 - accuracy: 0.3617 - val_loss: 1.5910 - val_accuracy: 0.3376

Epoch 00005: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 6/40
2112/2112 [==============================] - 240s 114ms/step - loss: 1.5620 - accuracy: 0.3679 - val_loss: 1.7329 - val_accuracy: 0.3139

Epoch 00006: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 7/40
2112/2112 [==============================] - 240s 114ms/step - loss: 1.5649 - accuracy: 0.3750 - val_loss: 1.4992 - val_accuracy: 0.3731

Epoch 00007: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 8/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.5795 - accuracy: 0.3494 - val_loss: 1.3369 - val_accuracy: 0.4872

Epoch 00008: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 9/40
2112/2112 [==============================] - 240s 114ms/step - loss: 1.4668 - accuracy: 0.4181 - val_loss: 1.3351 - val_accuracy: 0.4716

Epoch 00009: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 10/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.5150 - accuracy: 0.3873 - val_loss: 1.3652 - val_accuracy: 0.4588

Epoch 00010: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 11/40
2112/2112 [==============================] - 243s 115ms/step - loss: 1.4922 - accuracy: 0.4029 - val_loss: 1.4246 - val_accuracy: 0.4725

Epoch 00011: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 12/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4718 - accuracy: 0.4048 - val_loss: 1.4907 - val_accuracy: 0.3916

Epoch 00012: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 13/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4326 - accuracy: 0.4162 - val_loss: 1.2943 - val_accuracy: 0.4806

Epoch 00013: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 14/40
2112/2112 [==============================] - 240s 114ms/step - loss: 1.4250 - accuracy: 0.4318 - val_loss: 1.2521 - val_accuracy: 0.5147

Epoch 00014: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 15/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4288 - accuracy: 0.4162 - val_loss: 1.2913 - val_accuracy: 0.4882

Epoch 00015: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 16/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.4060 - accuracy: 0.4422 - val_loss: 1.3164 - val_accuracy: 0.4394

Epoch 00016: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 17/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3779 - accuracy: 0.4455 - val_loss: 1.1476 - val_accuracy: 0.5554

Epoch 00017: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 18/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3531 - accuracy: 0.4527 - val_loss: 1.2736 - val_accuracy: 0.5166

Epoch 00018: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 19/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3564 - accuracy: 0.4569 - val_loss: 1.2451 - val_accuracy: 0.4981

Epoch 00019: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 20/40
2112/2112 [==============================] - 253s 120ms/step - loss: 1.3451 - accuracy: 0.4706 - val_loss: 1.1494 - val_accuracy: 0.5450

Epoch 00020: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 21/40
2112/2112 [==============================] - 243s 115ms/step - loss: 1.3290 - accuracy: 0.4706 - val_loss: 1.2309 - val_accuracy: 0.5426

Epoch 00021: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 22/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.3013 - accuracy: 0.4863 - val_loss: 1.1225 - val_accuracy: 0.5687

Epoch 00022: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 23/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2924 - accuracy: 0.4811 - val_loss: 1.1293 - val_accuracy: 0.5705

Epoch 00023: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 24/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2758 - accuracy: 0.4901 - val_loss: 1.1227 - val_accuracy: 0.5781

Epoch 00024: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 25/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2331 - accuracy: 0.5118 - val_loss: 1.0431 - val_accuracy: 0.5909

Epoch 00025: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 26/40
2112/2112 [==============================] - 243s 115ms/step - loss: 1.2367 - accuracy: 0.5156 - val_loss: 1.0757 - val_accuracy: 0.5819

Epoch 00026: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 27/40
2112/2112 [==============================] - 242s 114ms/step - loss: 1.2053 - accuracy: 0.5185 - val_loss: 0.9876 - val_accuracy: 0.6174

Epoch 00027: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 28/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.2043 - accuracy: 0.5284 - val_loss: 1.0745 - val_accuracy: 0.5824

Epoch 00028: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 29/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1912 - accuracy: 0.5275 - val_loss: 0.9959 - val_accuracy: 0.6264

Epoch 00029: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 30/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1762 - accuracy: 0.5412 - val_loss: 0.9316 - val_accuracy: 0.6425

Epoch 00030: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 31/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1393 - accuracy: 0.5563 - val_loss: 0.8945 - val_accuracy: 0.6487

Epoch 00031: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 32/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1231 - accuracy: 0.5606 - val_loss: 0.9225 - val_accuracy: 0.6548

Epoch 00032: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 33/40
2112/2112 [==============================] - 241s 114ms/step - loss: 1.1187 - accuracy: 0.5616 - val_loss: 0.9196 - val_accuracy: 0.6577

Epoch 00033: saving model to 4_convdropout0.5densedropout0.2weights.hdf5
Epoch 34/40
2048/2112 [============================>.] - ETA: 4s - loss: 1.1081 - accuracy: 0.5635^CTraceback (most recent call last):
  File "experiments.py", line 125, in <module>
    newrundropoutexperiment(4,[0.5,0.3], [0.4,0.2], 40)
  File "experiments.py", line 106, in newrundropoutexperiment
    train_network(weights_file_out = path, epochs=epochnum, batch_size=64, val_split=0, convdropout=c, densdropout=d)
  File "experiments.py", line 63, in train_network
    verbose=1, callbacks=[checkpointer], validation_split=val_split, validation_data=(X_train, Y_train))
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training.py", line 1239, in fit
    validation_freq=validation_freq)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training_arrays.py", line 210, in fit_loop
    verbose=0)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training_arrays.py", line 449, in test_loop
    batch_outs = f(ins_batch)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py", line 3740, in __call__
    outputs = self._graph_fn(*converted_inputs)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1081, in __call__
    return self._call_impl(args, kwargs)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1121, in _call_impl
    return self._call_flat(args, self.captured_inputs, cancellation_manager)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 511, in call
    ctx=ctx)
  File "/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py", line 61, in quick_execute
    num_outputs)
KeyboardInterrupt
(tensorflow) Evangelie-2:panotti evangelie$ 
