Last login: Sat Dec  7 16:00:05 on ttys000
(base) Evangelie-2:~ evangelie$ cd ~/Documents/GitHub/panotti/
(base) Evangelie-2:panotti evangelie$ source activate tensorflow
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
['/Users/evangelie/Documents/GitHub/panotti', '/miniconda3/envs/tensorflow/lib/python37.zip', '/miniconda3/envs/tensorflow/lib/python3.7', '/miniconda3/envs/tensorflow/lib/python3.7/lib-dynload', '/Users/evangelie/.local/lib/python3.7/site-packages', '/miniconda3/envs/tensorflow/lib/python3.7/site-packages']
3.7.5 (default, Oct 25 2019, 10:52:18) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
Using TensorFlow backend.
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1040_TIE_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1077_ITH_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1052_IEO_ANG_LO. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1001_IOM_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1091_DFA_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1031_MTI_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1035_MTI_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1038_TAI_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1049_TSI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1046_IOM_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1086_IWL_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1054_IEO_FEA_LO. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1010_IEO_FEA_HI. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1068_IOM_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1087_IOM_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1077_IEO_HAP_MD.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1017_TAI_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1002_IWW_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1018_IWL_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1038_IEO_HAP_HI.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1088_IEO_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1057_TAI_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1051_IWW_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1052_IWW_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1018_IWW_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1042_TSI_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1005_IWW_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1025_IOM_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
2019-12-08 01:03:24.599773: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-08 01:03:24.600511: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_1 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_2 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_3 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_4 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_5 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 231s 113ms/step - loss: 4.2337 - accuracy: 0.2441

Epoch 00001: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 162s 79ms/step - loss: 2.1005 - accuracy: 0.2896

Epoch 00002: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 161s 79ms/step - loss: 1.9187 - accuracy: 0.3013

Epoch 00003: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.9319 - accuracy: 0.2969

Epoch 00004: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8065 - accuracy: 0.3247

Epoch 00005: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7332 - accuracy: 0.3335

Epoch 00006: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 173s 84ms/step - loss: 1.7456 - accuracy: 0.3115

Epoch 00007: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7098 - accuracy: 0.3350

Epoch 00008: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6790 - accuracy: 0.3521

Epoch 00009: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7041 - accuracy: 0.3613

Epoch 00010: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5968 - accuracy: 0.3574

Epoch 00011: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6102 - accuracy: 0.3701

Epoch 00012: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5620 - accuracy: 0.3735

Epoch 00013: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5614 - accuracy: 0.3892

Epoch 00014: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5390 - accuracy: 0.3955

Epoch 00015: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5543 - accuracy: 0.3887

Epoch 00016: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5613 - accuracy: 0.3638

Epoch 00017: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 163s 79ms/step - loss: 1.4806 - accuracy: 0.4146

Epoch 00018: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5213 - accuracy: 0.4077

Epoch 00019: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5166 - accuracy: 0.3931

Epoch 00020: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4767 - accuracy: 0.4038

Epoch 00021: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4239 - accuracy: 0.4263

Epoch 00022: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4440 - accuracy: 0.4238

Epoch 00023: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4369 - accuracy: 0.4258

Epoch 00024: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4360 - accuracy: 0.4351

Epoch 00025: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3770 - accuracy: 0.4585

Epoch 00026: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4051 - accuracy: 0.4414

Epoch 00027: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3903 - accuracy: 0.4575

Epoch 00028: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3571 - accuracy: 0.4644

Epoch 00029: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 173s 84ms/step - loss: 1.3669 - accuracy: 0.4639

Epoch 00030: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1077_IOM_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1085_IWW_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1074_IEO_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1001_IWW_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1082_DFA_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1004_ITH_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1057_ITS_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1051_IEO_HAP_HI.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1042_TSI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1070_TIE_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1065_IWW_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1049_ITS_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.312163157570631
Dev set accuracy: 0.5037593841552734
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1069_ITH_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1016_IOM_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1068_WSI_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1010_IEO_ANG_HI. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1024_IOM_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1005_TIE_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1035_MTI_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1037_DFA_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1057_TIE_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1046_IEO_DIS_MD.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1057_WSI_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1018_IEO_FEA_LO. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1004_WSI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1054_IOM_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1030_DFA_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1003_TIE_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1005_ITH_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1039_ITH_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1038_IOM_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1026_IWL_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1032_IOM_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1053_TIE_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1037_TSI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1062_WSI_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1056_IWW_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1013_WSI_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1022_ITS_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1064_TIE_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_6 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_7 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_8 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_9 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_10 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 163s 80ms/step - loss: 3.9659 - accuracy: 0.2339

Epoch 00001: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 160s 78ms/step - loss: 2.2963 - accuracy: 0.2622

Epoch 00002: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 160s 78ms/step - loss: 2.0476 - accuracy: 0.2905

Epoch 00003: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 160s 78ms/step - loss: 2.0155 - accuracy: 0.2881

Epoch 00004: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.9064 - accuracy: 0.3154

Epoch 00005: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8655 - accuracy: 0.3076

Epoch 00006: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8283 - accuracy: 0.3184

Epoch 00007: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7577 - accuracy: 0.3247

Epoch 00008: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7316 - accuracy: 0.3389

Epoch 00009: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.6741 - accuracy: 0.3481

Epoch 00010: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7031 - accuracy: 0.3325

Epoch 00011: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6263 - accuracy: 0.3530

Epoch 00012: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6483 - accuracy: 0.3472

Epoch 00013: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5827 - accuracy: 0.3740

Epoch 00014: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6189 - accuracy: 0.3672

Epoch 00015: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5880 - accuracy: 0.3779

Epoch 00016: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5766 - accuracy: 0.3716

Epoch 00017: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5395 - accuracy: 0.3906

Epoch 00018: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5210 - accuracy: 0.3828

Epoch 00019: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5123 - accuracy: 0.4004

Epoch 00020: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5310 - accuracy: 0.3931

Epoch 00021: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 167s 81ms/step - loss: 1.5132 - accuracy: 0.3862

Epoch 00022: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 166s 81ms/step - loss: 1.4849 - accuracy: 0.4131

Epoch 00023: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5050 - accuracy: 0.3975

Epoch 00024: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4886 - accuracy: 0.3975

Epoch 00025: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4644 - accuracy: 0.4067

Epoch 00026: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4675 - accuracy: 0.4062

Epoch 00027: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4174 - accuracy: 0.4419

Epoch 00028: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4408 - accuracy: 0.4272

Epoch 00029: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4132 - accuracy: 0.4380

Epoch 00030: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1090_TAI_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1039_TIE_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1019_TAI_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1024_IEO_DIS_MD.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1007_IEO_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1017_MTI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1045_TSI_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1085_TSI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1063_TIE_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1035_ITS_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1019_MTI_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1077_MTI_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.4297094174793787
Dev set accuracy: 0.3796992599964142
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1088_TSI_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1086_TIE_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1012_TAI_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1088_IOM_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1016_MTI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1051_IWW_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1091_IEO_DIS_HI. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1073_IEO_DIS_MD. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1024_IWW_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1046_IWW_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1078_IWW_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1078_IOM_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1066_TAI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1065_DFA_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1029_TIE_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1042_IWL_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1001_TAI_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1005_IWL_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1086_IOM_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1046_IWL_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1063_DFA_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1037_TIE_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1033_ITH_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1039_ITS_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1015_TAI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1024_TSI_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1046_WSI_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1010_ITH_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_11 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_12 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_13 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_14 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_15 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 163s 80ms/step - loss: 5.0627 - accuracy: 0.2349

Epoch 00001: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 159s 78ms/step - loss: 2.3636 - accuracy: 0.2524

Epoch 00002: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 163s 79ms/step - loss: 2.2159 - accuracy: 0.2720

Epoch 00003: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 159s 78ms/step - loss: 2.0788 - accuracy: 0.2769

Epoch 00004: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 160s 78ms/step - loss: 2.0281 - accuracy: 0.2900

Epoch 00005: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.9942 - accuracy: 0.2964

Epoch 00006: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8700 - accuracy: 0.3071

Epoch 00007: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8370 - accuracy: 0.3179

Epoch 00008: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7984 - accuracy: 0.3179

Epoch 00009: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 159s 78ms/step - loss: 1.7698 - accuracy: 0.3423

Epoch 00010: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7175 - accuracy: 0.3291

Epoch 00011: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6945 - accuracy: 0.3467

Epoch 00012: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6777 - accuracy: 0.3555

Epoch 00013: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 159s 78ms/step - loss: 1.6638 - accuracy: 0.3306

Epoch 00014: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 173s 84ms/step - loss: 1.6347 - accuracy: 0.3452

Epoch 00015: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6330 - accuracy: 0.3682

Epoch 00016: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 159s 78ms/step - loss: 1.5863 - accuracy: 0.3662

Epoch 00017: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5874 - accuracy: 0.3701

Epoch 00018: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5917 - accuracy: 0.3784

Epoch 00019: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5838 - accuracy: 0.3628

Epoch 00020: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5219 - accuracy: 0.3906

Epoch 00021: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5342 - accuracy: 0.3857

Epoch 00022: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 161s 78ms/step - loss: 1.5001 - accuracy: 0.3926

Epoch 00023: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 161s 79ms/step - loss: 1.5091 - accuracy: 0.3950

Epoch 00024: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 165s 81ms/step - loss: 1.4895 - accuracy: 0.4067

Epoch 00025: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 163s 79ms/step - loss: 1.4722 - accuracy: 0.3994

Epoch 00026: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.4892 - accuracy: 0.4033

Epoch 00027: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.4599 - accuracy: 0.4175

Epoch 00028: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.4705 - accuracy: 0.3955

Epoch 00029: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.4714 - accuracy: 0.4116

Epoch 00030: saving model to 6_convdropout0.6densedropout0.6weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1006_TSI_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1078_MTI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1060_TSI_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1033_WSI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1058_TAI_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1007_WSI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1069_ITS_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1055_MTI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1086_TSI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1086_MTI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1046_IWW_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1002_TSI_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.56339977289501
Dev set accuracy: 0.37593984603881836
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1056_MTI_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1073_IWW_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1021_ITS_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1056_IEO_ANG_MD. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1081_IOM_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1060_IOM_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1052_MTI_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1044_MTI_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1049_TSI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1025_MTI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1055_TAI_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1074_ITH_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1043_TSI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1071_TAI_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1035_ITS_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1052_ITS_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1054_TSI_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1008_IEO_HAP_MD. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1017_TIE_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1055_IWW_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1056_IWW_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1010_MTI_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1029_TAI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1080_IWW_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1062_WSI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1080_IOM_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1075_IEO_SAD_MD. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1057_IWL_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 48, 210, 32)       0         
_________________________________________________________________
activation_16 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_17 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_18 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_19 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_20 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 167s 81ms/step - loss: 4.3414 - accuracy: 0.2227

Epoch 00001: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 163s 80ms/step - loss: 2.5358 - accuracy: 0.2500

Epoch 00002: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 163s 80ms/step - loss: 2.3726 - accuracy: 0.2559

Epoch 00003: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 163s 80ms/step - loss: 2.1989 - accuracy: 0.2749

Epoch 00004: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 163s 80ms/step - loss: 2.1028 - accuracy: 0.3027

Epoch 00005: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 163s 80ms/step - loss: 2.0684 - accuracy: 0.2852

Epoch 00006: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.9852 - accuracy: 0.2939

Epoch 00007: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 176s 86ms/step - loss: 1.9613 - accuracy: 0.3037

Epoch 00008: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.8607 - accuracy: 0.3091

Epoch 00009: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 162s 79ms/step - loss: 1.8880 - accuracy: 0.3125

Epoch 00010: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 161s 78ms/step - loss: 1.8082 - accuracy: 0.3071

Epoch 00011: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7519 - accuracy: 0.3354

Epoch 00012: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7435 - accuracy: 0.3325

Epoch 00013: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6735 - accuracy: 0.3472

Epoch 00014: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6912 - accuracy: 0.3486

Epoch 00015: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6906 - accuracy: 0.3315

Epoch 00016: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.6621 - accuracy: 0.3506

Epoch 00017: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 159s 78ms/step - loss: 1.6356 - accuracy: 0.3667

Epoch 00018: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6529 - accuracy: 0.3442

Epoch 00019: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6001 - accuracy: 0.3667

Epoch 00020: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5755 - accuracy: 0.3730

Epoch 00021: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5847 - accuracy: 0.3550

Epoch 00022: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5267 - accuracy: 0.3838

Epoch 00023: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5376 - accuracy: 0.3770

Epoch 00024: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5177 - accuracy: 0.3901

Epoch 00025: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5140 - accuracy: 0.3799

Epoch 00026: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5213 - accuracy: 0.3892

Epoch 00027: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4895 - accuracy: 0.4043

Epoch 00028: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4924 - accuracy: 0.3853

Epoch 00029: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4917 - accuracy: 0.4033

Epoch 00030: saving model to 6_convdropout0.6densedropout0.7weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1062_TIE_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1066_IWL_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1088_ITS_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1002_ITH_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1017_IEO_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1090_TAI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1075_TSI_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1076_IOM_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1048_TSI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1036_IEO_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1086_IEO_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1019_IEO_SAD_HI.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.4607975698055182
Dev set accuracy: 0.37593984603881836
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1046_DFA_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1057_ITH_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1055_WSI_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1052_TIE_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1079_IWL_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1060_IEO_DIS_LO.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1048_TIE_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1004_IWL_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1008_IWL_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1056_ITS_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1008_MTI_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1003_IWL_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1040_DFA_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1023_MTI_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1081_TIE_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1012_TAI_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1014_IWW_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1079_WSI_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1028_IWL_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1083_IEO_HAP_HI.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1028_IEO_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1018_TIE_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1054_TSI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1091_TSI_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1013_DFA_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1017_IEO_SAD_HI.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1048_IEO_SAD_LO. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1055_ITS_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 48, 210, 32)       0         
_________________________________________________________________
activation_21 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_22 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_23 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_24 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_9 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_25 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 174s 85ms/step - loss: 3.3445 - accuracy: 0.2715

Epoch 00001: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8287 - accuracy: 0.3013

Epoch 00002: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7652 - accuracy: 0.3242

Epoch 00003: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7097 - accuracy: 0.3325

Epoch 00004: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6707 - accuracy: 0.3589

Epoch 00005: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6310 - accuracy: 0.3560

Epoch 00006: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 161s 78ms/step - loss: 1.5636 - accuracy: 0.3735

Epoch 00007: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5867 - accuracy: 0.3701

Epoch 00008: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 164s 80ms/step - loss: 1.5868 - accuracy: 0.3687

Epoch 00009: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 164s 80ms/step - loss: 1.5925 - accuracy: 0.3696

Epoch 00010: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5545 - accuracy: 0.3848

Epoch 00011: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5100 - accuracy: 0.3906

Epoch 00012: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4588 - accuracy: 0.4116

Epoch 00013: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4509 - accuracy: 0.4136

Epoch 00014: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4415 - accuracy: 0.4189

Epoch 00015: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4267 - accuracy: 0.4438

Epoch 00016: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4565 - accuracy: 0.4282

Epoch 00017: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3889 - accuracy: 0.4517

Epoch 00018: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4033 - accuracy: 0.4326

Epoch 00019: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3654 - accuracy: 0.4595

Epoch 00020: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3453 - accuracy: 0.4824

Epoch 00021: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4053 - accuracy: 0.4492

Epoch 00022: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 166s 81ms/step - loss: 1.3802 - accuracy: 0.4683

Epoch 00023: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 167s 81ms/step - loss: 1.3600 - accuracy: 0.4639

Epoch 00024: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3156 - accuracy: 0.4888

Epoch 00025: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2974 - accuracy: 0.4839

Epoch 00026: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3167 - accuracy: 0.4653

Epoch 00027: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2773 - accuracy: 0.4951

Epoch 00028: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2957 - accuracy: 0.4951

Epoch 00029: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2641 - accuracy: 0.5068

Epoch 00030: saving model to 6_convdropout0.4densedropout0.6weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1064_IWW_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1028_IWW_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1076_MTI_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1053_IEO_DIS_MD.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1062_DFA_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1076_TIE_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1057_ITS_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1008_DFA_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1042_TSI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1043_IWW_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1061_WSI_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1041_IEO_SAD_LO.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.407641011073177
Dev set accuracy: 0.4285714328289032
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1081_IWW_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1017_IEO_ANG_HI. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1035_TSI_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1021_ITS_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1071_IEO_ANG_HI.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1021_IEO_DIS_MD.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1080_IEO_DIS_LO. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1082_DFA_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1045_IEO_DIS_HI. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1083_TSI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1024_TAI_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1024_WSI_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1011_IWL_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1029_IOM_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1036_IWW_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1008_IEO_HAP_MD.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1048_IEO_HAP_HI. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1086_DFA_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1029_IEO_HAP_MD. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1007_TIE_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1001_TIE_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1006_ITS_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1021_MTI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1091_IOM_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1081_WSI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1066_ITH_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1007_TIE_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1062_WSI_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 48, 210, 32)       0         
_________________________________________________________________
activation_26 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_27 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_28 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_22 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_29 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 128)               639104    
_________________________________________________________________
activation_30 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_24 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 164s 80ms/step - loss: 3.3286 - accuracy: 0.2422

Epoch 00001: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 163s 80ms/step - loss: 2.0698 - accuracy: 0.2681

Epoch 00002: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8871 - accuracy: 0.2876

Epoch 00003: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7847 - accuracy: 0.3257

Epoch 00004: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7732 - accuracy: 0.3257

Epoch 00005: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7558 - accuracy: 0.3037

Epoch 00006: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6563 - accuracy: 0.3638

Epoch 00007: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6426 - accuracy: 0.3442

Epoch 00008: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6219 - accuracy: 0.3755

Epoch 00009: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6169 - accuracy: 0.3760

Epoch 00010: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6047 - accuracy: 0.3745

Epoch 00011: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5805 - accuracy: 0.3677

Epoch 00012: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5369 - accuracy: 0.3989

Epoch 00013: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5360 - accuracy: 0.3882

Epoch 00014: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5125 - accuracy: 0.4043

Epoch 00015: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 173s 84ms/step - loss: 1.4866 - accuracy: 0.4131

Epoch 00016: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4785 - accuracy: 0.4116

Epoch 00017: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4616 - accuracy: 0.4185

Epoch 00018: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4243 - accuracy: 0.4419

Epoch 00019: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4199 - accuracy: 0.4482

Epoch 00020: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4091 - accuracy: 0.4531

Epoch 00021: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4135 - accuracy: 0.4443

Epoch 00022: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3729 - accuracy: 0.4609

Epoch 00023: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3824 - accuracy: 0.4502

Epoch 00024: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.3948 - accuracy: 0.4536

Epoch 00025: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3345 - accuracy: 0.4722

Epoch 00026: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3370 - accuracy: 0.4751

Epoch 00027: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3567 - accuracy: 0.4722

Epoch 00028: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3233 - accuracy: 0.5020

Epoch 00029: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3175 - accuracy: 0.4858

Epoch 00030: saving model to 6_convdropout0.4densedropout0.7weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1018_TAI_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1029_IEO_ANG_HI.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1074_ITH_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1076_MTI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1023_TIE_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1058_ITS_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1058_IWL_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1066_MTI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1075_MTI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1021_TSI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1053_ITS_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1039_TSI_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.25905486246697
Dev set accuracy: 0.5075187683105469
(tensorflow) Evangelie-2:panotti evangelie$  
