Last login: Sun Dec  8 01:02:47 on ttys001
(base) Evangelie-2:~ evangelie$ python experiments.py
python: can't open file 'experiments.py': [Errno 2] No such file or directory
(base) Evangelie-2:~ evangelie$ cd ~/Documents/GitHub/panotti/
(base) Evangelie-2:panotti evangelie$ source activate tensorflow
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
  File "experiments.py", line 119
    outpath = str(version.5)+"_convdropout"+str(c) + "densedropout"+str(d) +"weights.hdf5"
                          ^
SyntaxError: invalid syntax
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
['/Users/evangelie/Documents/GitHub/panotti', '/miniconda3/envs/tensorflow/lib/python37.zip', '/miniconda3/envs/tensorflow/lib/python3.7', '/miniconda3/envs/tensorflow/lib/python3.7/lib-dynload', '/Users/evangelie/.local/lib/python3.7/site-packages', '/miniconda3/envs/tensorflow/lib/python3.7/site-packages']
3.7.5 (default, Oct 25 2019, 10:52:18) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
Using TensorFlow backend.
Traceback (most recent call last):
  File "experiments.py", line 145, in <module>
    continuerundropoutexperiment(6,[0.5], [0.6,0.7],10,128)
TypeError: continuerundropoutexperiment() takes 4 positional arguments but 5 were given
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
['/Users/evangelie/Documents/GitHub/panotti', '/miniconda3/envs/tensorflow/lib/python37.zip', '/miniconda3/envs/tensorflow/lib/python3.7', '/miniconda3/envs/tensorflow/lib/python3.7/lib-dynload', '/Users/evangelie/.local/lib/python3.7/site-packages', '/miniconda3/envs/tensorflow/lib/python3.7/site-packages']
3.7.5 (default, Oct 25 2019, 10:52:18) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
Using TensorFlow backend.
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1083_IWW_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1053_IWL_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1030_IEO_ANG_HI. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1047_TAI_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1013_DFA_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1026_MTI_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1023_IEO_DIS_LO. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1035_IEO_DIS_MD. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1032_IEO_DIS_LO. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1023_IWW_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1061_IOM_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1065_IOM_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1040_DFA_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1088_WSI_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1054_IWL_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1041_TSI_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1050_ITH_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1037_TIE_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1011_IEO_HAP_HI. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1067_TSI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1045_ITH_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1079_ITS_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1087_MTI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1013_ITH_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1005_ITH_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1072_TSI_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1013_IOM_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1077_IEO_SAD_MD.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
2019-12-08 11:19:14.240345: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-08 11:19:14.240666: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
Weights file detected. Loading from  6_convdropout0.5densedropout0.6weights.hdf5
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_1 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_2 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_3 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_4 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_5 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/10
2048/2048 [==============================] - 166s 81ms/step - loss: 1.3963 - accuracy: 0.4380

Epoch 00001: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 2/10
2048/2048 [==============================] - 166s 81ms/step - loss: 1.4017 - accuracy: 0.4399

Epoch 00002: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 3/10
2048/2048 [==============================] - 163s 80ms/step - loss: 1.3982 - accuracy: 0.4434

Epoch 00003: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 4/10
2048/2048 [==============================] - 162s 79ms/step - loss: 1.3655 - accuracy: 0.4590

Epoch 00004: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 5/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3479 - accuracy: 0.4624

Epoch 00005: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 6/10
2048/2048 [==============================] - 164s 80ms/step - loss: 1.3418 - accuracy: 0.4619

Epoch 00006: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 7/10
2048/2048 [==============================] - 168s 82ms/step - loss: 1.3375 - accuracy: 0.4692

Epoch 00007: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 8/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2981 - accuracy: 0.4902

Epoch 00008: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 9/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3236 - accuracy: 0.4790

Epoch 00009: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
Epoch 10/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3337 - accuracy: 0.4810

Epoch 00010: saving model to 6_convdropout0.5densedropout0.6weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1019_DFA_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1051_ITH_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1081_IEO_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1030_TIE_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1059_ITS_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1083_TSI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1075_TSI_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1008_DFA_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1019_DFA_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1043_IWW_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1037_IEO_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1041_IEO_SAD_LO.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.3454343770679675
Dev set accuracy: 0.49248120188713074
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1021_IEO_ANG_HI.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1073_IEO_ANG_MD. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1054_ITS_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1015_ITH_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1063_IWW_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1029_IEO_DIS_LO.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1069_WSI_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1037_DFA_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1014_TIE_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1018_TIE_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1058_IWW_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1037_IOM_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1063_TSI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1030_ITS_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1066_ITH_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1066_IEO_HAP_LO.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1078_WSI_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1074_TAI_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1050_IEO_HAP_MD. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1091_IOM_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1087_IOM_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1015_WSI_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1084_IOM_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1079_WSI_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1051_IOM_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1011_IWL_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1085_DFA_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1026_IWL_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
Weights file detected. Loading from  6_convdropout0.5densedropout0.7weights.hdf5
WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_6 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_7 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_8 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_9 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_10 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/10
2048/2048 [==============================] - 171s 83ms/step - loss: 1.4677 - accuracy: 0.4316

Epoch 00001: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 2/10
2048/2048 [==============================] - 167s 82ms/step - loss: 1.4810 - accuracy: 0.4131

Epoch 00002: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 3/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4228 - accuracy: 0.4380

Epoch 00003: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 4/10
2048/2048 [==============================] - 164s 80ms/step - loss: 1.4396 - accuracy: 0.4277

Epoch 00004: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 5/10
2048/2048 [==============================] - 161s 79ms/step - loss: 1.3685 - accuracy: 0.4580

Epoch 00005: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 6/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3778 - accuracy: 0.4556

Epoch 00006: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 7/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3667 - accuracy: 0.4556

Epoch 00007: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 8/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3488 - accuracy: 0.4541

Epoch 00008: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 9/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3233 - accuracy: 0.4771

Epoch 00009: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
Epoch 10/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3459 - accuracy: 0.4644

Epoch 00010: saving model to 6_convdropout0.5densedropout0.7weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1069_IOM_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1028_IWW_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1001_IWW_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1053_IEO_DIS_MD.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1075_ITH_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1058_ITS_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1057_ITS_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1045_TSI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1086_TSI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1019_DFA_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1041_IEO_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1061_WSI_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.3145108599411814
Dev set accuracy: 0.49248120188713074
Traceback (most recent call last):
  File "experiments.py", line 146, in <module>
    #newrundropoutexperiment(4,[0.5,0.3], [0.4,0.2], 40)
  File "experiments.py", line 120, in newnewrundropoutexperiment
    inpath = str(version)+"_convdropout"+str(c) + "densedropout"+str(d) +"weights.hdf5"
NameError: name 'path' is not defined
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
  File "experiments.py", line 153
    newrunoptimizerexperiment(8, ["Adam"], [0.001, 0.0001],"" 40, 128)
                                                               ^
SyntaxError: invalid syntax
(tensorflow) Evangelie-2:panotti evangelie$ python experiments.py
['/Users/evangelie/Documents/GitHub/panotti', '/miniconda3/envs/tensorflow/lib/python37.zip', '/miniconda3/envs/tensorflow/lib/python3.7', '/miniconda3/envs/tensorflow/lib/python3.7/lib-dynload', '/Users/evangelie/.local/lib/python3.7/site-packages', '/miniconda3/envs/tensorflow/lib/python3.7/site-packages']
3.7.5 (default, Oct 25 2019, 10:52:18) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
Using TensorFlow backend.
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1072_ITH_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1009_TSI_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1042_IEO_ANG_HI. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1085_IWL_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1078_IOM_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1014_IEO_DIS_MD.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1009_WSI_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1028_ITH_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1031_IWL_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1026_TIE_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1041_IOM_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1012_TSI_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1050_TAI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1078_TSI_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1057_WSI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1079_WSI_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1069_IEO_HAP_HI. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1073_ITH_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1004_IEO_HAP_MD. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1039_ITH_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1051_WSI_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1051_IWW_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1046_ITS_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1005_TIE_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1083_TSI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1034_DFA_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1016_IEO_SAD_HI. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1028_DFA_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
2019-12-08 12:21:08.100609: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-08 12:21:08.100916: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
Weights file detected. Loading from  6_convdropout0.5densedropout0.6weights.hdf5
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_1 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_2 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_3 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_4 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_5 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/10
2048/2048 [==============================] - 164s 80ms/step - loss: 1.2473 - accuracy: 0.5195

Epoch 00001: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 2/10
2048/2048 [==============================] - 161s 78ms/step - loss: 1.2627 - accuracy: 0.5137

Epoch 00002: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 3/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2348 - accuracy: 0.5200

Epoch 00003: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 4/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2247 - accuracy: 0.5205

Epoch 00004: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 5/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2165 - accuracy: 0.5166

Epoch 00005: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 6/10
2048/2048 [==============================] - 168s 82ms/step - loss: 1.1994 - accuracy: 0.5347

Epoch 00006: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 7/10
2048/2048 [==============================] - 165s 80ms/step - loss: 1.2140 - accuracy: 0.5347

Epoch 00007: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 8/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.1695 - accuracy: 0.5474

Epoch 00008: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 9/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.1968 - accuracy: 0.5366

Epoch 00009: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
Epoch 10/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.1792 - accuracy: 0.5396

Epoch 00010: saving model to 60.5_convdropout0.5densedropout0.6weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1085_IWW_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1009_TAI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1020_DFA_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1042_IWW_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1080_IEO_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1069_TAI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1026_IOM_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1009_WSI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1070_TIE_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1036_IEO_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1057_WSI_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1049_ITS_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.30695659056642
Dev set accuracy: 0.5075187683105469
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1085_TIE_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1021_MTI_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1085_IWL_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1063_ITH_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1085_IOM_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1032_WSI_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1078_WSI_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1074_IEO_DIS_MD. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1081_TAI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1020_IEO_DIS_LO.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1004_WSI_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1032_TAI_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1065_IOM_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1054_TIE_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1060_IEO_FEA_HI.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1038_IOM_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1002_IEO_HAP_MD. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1014_TSI_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1018_TIE_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1013_IWL_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1007_DFA_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1025_ITS_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1045_IOM_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1074_TSI_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1026_MTI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1010_IWL_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1081_IEO_SAD_MD. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1055_DFA_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
Weights file detected. Loading from  6_convdropout0.5densedropout0.7weights.hdf5
WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_6 (Activation)    (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 24, 105, 32)       0         
_________________________________________________________________
activation_7 (Activation)    (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 12, 52, 32)        0         
_________________________________________________________________
activation_8 (Activation)    (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 6, 26, 32)         0         
_________________________________________________________________
activation_9 (Activation)    (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_10 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/10
2048/2048 [==============================] - 164s 80ms/step - loss: 1.2714 - accuracy: 0.5034

Epoch 00001: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 2/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2951 - accuracy: 0.4893

Epoch 00002: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 3/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2944 - accuracy: 0.4946

Epoch 00003: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 4/10
2048/2048 [==============================] - 164s 80ms/step - loss: 1.3166 - accuracy: 0.4888

Epoch 00004: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 5/10
2048/2048 [==============================] - 161s 78ms/step - loss: 1.2864 - accuracy: 0.5000

Epoch 00005: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 6/10
2048/2048 [==============================] - 161s 78ms/step - loss: 1.2724 - accuracy: 0.5054

Epoch 00006: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 7/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2214 - accuracy: 0.5239

Epoch 00007: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 8/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2516 - accuracy: 0.5083

Epoch 00008: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 9/10
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2308 - accuracy: 0.5200

Epoch 00009: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
Epoch 10/10
2048/2048 [==============================] - 161s 78ms/step - loss: 1.2405 - accuracy: 0.5234

Epoch 00010: saving model to 60.5_convdropout0.5densedropout0.7weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1034_IEO_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1009_TAI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1044_IWL_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1078_ITS_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1027_IOM_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1036_TAI_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1059_DFA_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1012_IEO_HAP_LO.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1083_IWL_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1054_ITS_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1061_WSI_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1062_TIE_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.255411219776125
Dev set accuracy: 0.518796980381012
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1054_IEO_ANG_MD.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1027_IWW_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1041_DFA_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1077_IEO_ANG_LO. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1088_TSI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1057_IEO_DIS_HI.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1020_IWL_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1006_IEO_DIS_LO. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1080_TSI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1076_IEO_DIS_MD.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1063_IEO_FEA_LO.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1024_TAI_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1024_IEO_FEA_MD. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1085_MTI_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1085_IEO_FEA_MD.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1005_ITH_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1065_WSI_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1032_IEO_HAP_LO. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1066_IEO_HAP_LO. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1090_TSI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1050_MTI_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1090_TIE_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1074_WSI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1058_ITS_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1018_IWW_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1012_TSI_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1084_IEO_SAD_HI. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1058_IEO_SAD_LO.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 48, 210, 32)       0         
_________________________________________________________________
activation_11 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_12 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_13 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_14 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_15 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 164s 80ms/step - loss: 3.9386 - accuracy: 0.2358

Epoch 00001: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8047 - accuracy: 0.2993

Epoch 00002: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.7275 - accuracy: 0.3394

Epoch 00003: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6504 - accuracy: 0.3457

Epoch 00004: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6047 - accuracy: 0.3579

Epoch 00005: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6189 - accuracy: 0.3550

Epoch 00006: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5756 - accuracy: 0.3569

Epoch 00007: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6005 - accuracy: 0.3682

Epoch 00008: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 173s 84ms/step - loss: 1.5425 - accuracy: 0.3843

Epoch 00009: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5102 - accuracy: 0.3901

Epoch 00010: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4727 - accuracy: 0.3926

Epoch 00011: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5341 - accuracy: 0.4087

Epoch 00012: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5017 - accuracy: 0.4204

Epoch 00013: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4299 - accuracy: 0.4312

Epoch 00014: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4583 - accuracy: 0.4141

Epoch 00015: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.4351 - accuracy: 0.4263

Epoch 00016: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4762 - accuracy: 0.4355

Epoch 00017: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3989 - accuracy: 0.4263

Epoch 00018: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3540 - accuracy: 0.4614

Epoch 00019: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3697 - accuracy: 0.4653

Epoch 00020: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3425 - accuracy: 0.4839

Epoch 00021: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3328 - accuracy: 0.4712

Epoch 00022: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2933 - accuracy: 0.4868

Epoch 00023: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3191 - accuracy: 0.4893

Epoch 00024: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3172 - accuracy: 0.4751

Epoch 00025: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 161s 79ms/step - loss: 1.2586 - accuracy: 0.5142

Epoch 00026: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3081 - accuracy: 0.4814

Epoch 00027: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2815 - accuracy: 0.5020

Epoch 00028: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2625 - accuracy: 0.5083

Epoch 00029: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2253 - accuracy: 0.5181

Epoch 00030: saving model to 7_convdropout0.4densedropout0.5weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1041_IWW_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1018_TAI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1060_TSI_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1005_IEO_DIS_MD.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1053_IOM_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1063_DFA_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1033_MTI_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1008_ITS_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1042_TSI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1075_MTI_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1019_MTI_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1077_MTI_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.318586478556009
Dev set accuracy: 0.44736841320991516
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1068_DFA_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1001_IOM_ANG_XX. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1008_DFA_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1014_MTI_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1034_IOM_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1050_IEO_DIS_LO.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1028_ITH_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1045_IEO_DIS_MD. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1022_WSI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1023_IEO_DIS_LO.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1025_TSI_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1054_IEO_FEA_MD. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1042_IEO_FEA_HI. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1008_TSI_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1024_IWW_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1052_IEO_HAP_HI.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1034_ITS_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1088_ITH_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1030_TAI_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1041_ITS_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1071_IWW_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1023_ITS_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1085_TAI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1058_ITH_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1078_ITH_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1076_TIE_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1038_IEO_SAD_HI. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1033_IEO_SAD_MD.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 48, 210, 32)       0         
_________________________________________________________________
activation_16 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_17 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_18 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_19 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_20 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/30
2048/2048 [==============================] - 164s 80ms/step - loss: 2.9350 - accuracy: 0.2554

Epoch 00001: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 2/30
2048/2048 [==============================] - 173s 84ms/step - loss: 1.7432 - accuracy: 0.3052

Epoch 00002: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 3/30
2048/2048 [==============================] - 164s 80ms/step - loss: 1.6635 - accuracy: 0.3433

Epoch 00003: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 4/30
2048/2048 [==============================] - 161s 78ms/step - loss: 1.6502 - accuracy: 0.3467

Epoch 00004: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 5/30
2048/2048 [==============================] - 164s 80ms/step - loss: 1.5749 - accuracy: 0.3828

Epoch 00005: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 6/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.5131 - accuracy: 0.3813

Epoch 00006: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 7/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6204 - accuracy: 0.3706

Epoch 00007: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 8/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4510 - accuracy: 0.4150

Epoch 00008: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 9/30
2048/2048 [==============================] - 163s 80ms/step - loss: 1.4685 - accuracy: 0.4199

Epoch 00009: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 10/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4915 - accuracy: 0.4248

Epoch 00010: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 11/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3815 - accuracy: 0.4717

Epoch 00011: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 12/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3721 - accuracy: 0.4585

Epoch 00012: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 13/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4631 - accuracy: 0.4409

Epoch 00013: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 14/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3609 - accuracy: 0.4688

Epoch 00014: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 15/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3162 - accuracy: 0.4795

Epoch 00015: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 16/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2957 - accuracy: 0.4966

Epoch 00016: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 17/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3588 - accuracy: 0.4692

Epoch 00017: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 18/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2849 - accuracy: 0.4922

Epoch 00018: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 19/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3006 - accuracy: 0.4902

Epoch 00019: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 20/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2385 - accuracy: 0.5083

Epoch 00020: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 21/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2362 - accuracy: 0.5273

Epoch 00021: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 22/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2219 - accuracy: 0.5181

Epoch 00022: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 23/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2318 - accuracy: 0.5273

Epoch 00023: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 24/30
2048/2048 [==============================] - 164s 80ms/step - loss: 1.2054 - accuracy: 0.5371

Epoch 00024: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 25/30
2048/2048 [==============================] - 169s 82ms/step - loss: 1.2561 - accuracy: 0.5229

Epoch 00025: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 26/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.1197 - accuracy: 0.5635

Epoch 00026: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 27/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.1286 - accuracy: 0.5669

Epoch 00027: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 28/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.0880 - accuracy: 0.5952

Epoch 00028: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 29/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.0760 - accuracy: 0.5874

Epoch 00029: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
Epoch 30/30
2048/2048 [==============================] - 160s 78ms/step - loss: 1.1011 - accuracy: 0.5786

Epoch 00030: saving model to 7_convdropout0.3densedropout0.5weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1041_IWW_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1006_TSI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1001_IWW_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1048_MTI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1044_TSI_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1074_IWL_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1008_ITS_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1051_TIE_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1076_MTI_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1026_TIE_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1083_ITS_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1077_MTI_SAD_XX.wav.npz                  
adadelta  gives the following results:
Dev set loss: 1.3372143601116382
Dev set accuracy: 0.5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1022_IEO_ANG_HI.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1083_IEO_ANG_HI. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1015_ITH_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1043_TIE_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1064_IEO_ANG_MD.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1003_WSI_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1043_IWL_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1088_IWW_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1076_IOM_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1086_DFA_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1046_DFA_FEA_XX.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1033_IEO_FEA_LO. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1062_TAI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1020_IOM_FEA_XX. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1083_IWW_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1076_ITS_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1064_IEO_HAP_LO. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1066_ITH_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1017_ITS_HAP_XX. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1055_DFA_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1049_IOM_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1067_TIE_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1016_TSI_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1053_TIE_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1008_IOM_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1012_IEO_SAD_LO.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1062_DFA_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1081_IEO_SAD_HI.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 48, 210, 32)       0         
_________________________________________________________________
activation_21 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_22 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_23 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_24 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_9 (Dense)              (None, 128)               639104    
_________________________________________________________________
activation_25 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/40
2048/2048 [==============================] - 167s 81ms/step - loss: 3.5616 - accuracy: 0.2471

Epoch 00001: saving model to 8Adam0.001weights.hdf5
Epoch 2/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.8508 - accuracy: 0.2974

Epoch 00002: saving model to 8Adam0.001weights.hdf5
Epoch 3/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6972 - accuracy: 0.3345

Epoch 00003: saving model to 8Adam0.001weights.hdf5
Epoch 4/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.6319 - accuracy: 0.3433

Epoch 00004: saving model to 8Adam0.001weights.hdf5
Epoch 5/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5983 - accuracy: 0.3613

Epoch 00005: saving model to 8Adam0.001weights.hdf5
Epoch 6/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5388 - accuracy: 0.3657

Epoch 00006: saving model to 8Adam0.001weights.hdf5
Epoch 7/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5289 - accuracy: 0.3833

Epoch 00007: saving model to 8Adam0.001weights.hdf5
Epoch 8/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5360 - accuracy: 0.3818

Epoch 00008: saving model to 8Adam0.001weights.hdf5
Epoch 9/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4987 - accuracy: 0.4092

Epoch 00009: saving model to 8Adam0.001weights.hdf5
Epoch 10/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4927 - accuracy: 0.4141

Epoch 00010: saving model to 8Adam0.001weights.hdf5
Epoch 11/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4980 - accuracy: 0.4014

Epoch 00011: saving model to 8Adam0.001weights.hdf5
Epoch 12/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4454 - accuracy: 0.4287

Epoch 00012: saving model to 8Adam0.001weights.hdf5
Epoch 13/40
2048/2048 [==============================] - 161s 79ms/step - loss: 1.4268 - accuracy: 0.4292

Epoch 00013: saving model to 8Adam0.001weights.hdf5
Epoch 14/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3989 - accuracy: 0.4531

Epoch 00014: saving model to 8Adam0.001weights.hdf5
Epoch 15/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4379 - accuracy: 0.4238

Epoch 00015: saving model to 8Adam0.001weights.hdf5
Epoch 16/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3766 - accuracy: 0.4453

Epoch 00016: saving model to 8Adam0.001weights.hdf5
Epoch 17/40
2048/2048 [==============================] - 173s 84ms/step - loss: 1.3864 - accuracy: 0.4521

Epoch 00017: saving model to 8Adam0.001weights.hdf5
Epoch 18/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4062 - accuracy: 0.4507

Epoch 00018: saving model to 8Adam0.001weights.hdf5
Epoch 19/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3642 - accuracy: 0.4570

Epoch 00019: saving model to 8Adam0.001weights.hdf5
Epoch 20/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3564 - accuracy: 0.4585

Epoch 00020: saving model to 8Adam0.001weights.hdf5
Epoch 21/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3310 - accuracy: 0.4854

Epoch 00021: saving model to 8Adam0.001weights.hdf5
Epoch 22/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3386 - accuracy: 0.4673

Epoch 00022: saving model to 8Adam0.001weights.hdf5
Epoch 23/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3353 - accuracy: 0.4590

Epoch 00023: saving model to 8Adam0.001weights.hdf5
Epoch 24/40
2048/2048 [==============================] - 163s 79ms/step - loss: 1.3213 - accuracy: 0.4707

Epoch 00024: saving model to 8Adam0.001weights.hdf5
Epoch 25/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3037 - accuracy: 0.4946

Epoch 00025: saving model to 8Adam0.001weights.hdf5
Epoch 26/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.3046 - accuracy: 0.4766

Epoch 00026: saving model to 8Adam0.001weights.hdf5
Epoch 27/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.2931 - accuracy: 0.4829

Epoch 00027: saving model to 8Adam0.001weights.hdf5
Epoch 28/40
2048/2048 [==============================] - 163s 79ms/step - loss: 1.2727 - accuracy: 0.5020

Epoch 00028: saving model to 8Adam0.001weights.hdf5
Epoch 29/40
2048/2048 [==============================] - 161s 79ms/step - loss: 1.2719 - accuracy: 0.4868

Epoch 00029: saving model to 8Adam0.001weights.hdf5
Epoch 30/40
2048/2048 [==============================] - 173s 85ms/step - loss: 1.2494 - accuracy: 0.5186

Epoch 00030: saving model to 8Adam0.001weights.hdf5
Epoch 31/40
2048/2048 [==============================] - 164s 80ms/step - loss: 1.2267 - accuracy: 0.5161

Epoch 00031: saving model to 8Adam0.001weights.hdf5
Epoch 32/40
2048/2048 [==============================] - 168s 82ms/step - loss: 1.2431 - accuracy: 0.5195

Epoch 00032: saving model to 8Adam0.001weights.hdf5
Epoch 33/40
2048/2048 [==============================] - 168s 82ms/step - loss: 1.2042 - accuracy: 0.5303

Epoch 00033: saving model to 8Adam0.001weights.hdf5
Epoch 34/40
2048/2048 [==============================] - 172s 84ms/step - loss: 1.1974 - accuracy: 0.5332

Epoch 00034: saving model to 8Adam0.001weights.hdf5
Epoch 35/40
2048/2048 [==============================] - 169s 83ms/step - loss: 1.2185 - accuracy: 0.5103

Epoch 00035: saving model to 8Adam0.001weights.hdf5
Epoch 36/40
2048/2048 [==============================] - 161s 78ms/step - loss: 1.2079 - accuracy: 0.5244

Epoch 00036: saving model to 8Adam0.001weights.hdf5
Epoch 37/40
2048/2048 [==============================] - 169s 83ms/step - loss: 1.1644 - accuracy: 0.5483

Epoch 00037: saving model to 8Adam0.001weights.hdf5
Epoch 38/40
2048/2048 [==============================] - 171s 84ms/step - loss: 1.1620 - accuracy: 0.5503

Epoch 00038: saving model to 8Adam0.001weights.hdf5
Epoch 39/40
2048/2048 [==============================] - 168s 82ms/step - loss: 1.1704 - accuracy: 0.5410

Epoch 00039: saving model to 8Adam0.001weights.hdf5
Epoch 40/40
2048/2048 [==============================] - 187s 91ms/step - loss: 1.1261 - accuracy: 0.5576

Epoch 00040: saving model to 8Adam0.001weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1073_ITS_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1039_ITS_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1056_TSI_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1074_ITH_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1033_IWW_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1038_IEO_FEA_HI.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1015_TSI_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1058_WSI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1075_DFA_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1088_IOM_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1055_IEO_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1041_IEO_SAD_LO.wav.npz                  
Adam  gives the following results:
Dev set loss: 1.3293002834893708
Dev set accuracy: 0.45864662528038025
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  2126 , going to load total_load =  2048
total files =  2126 , going to load total_load =  2048
   get_sample_dimensions: 1068_DFA_ANG_XX.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/345: Preprocessed/Train/ANG/1080_IWL_ANG_XX.wa Loading class 1/6: 'ANG', File 101/345: Preprocessed/Train/ANG/1071_IEO_ANG_HI. Loading class 1/6: 'ANG', File 201/345: Preprocessed/Train/ANG/1004_IWW_ANG_XX. Loading class 1/6: 'ANG', File 301/345: Preprocessed/Train/ANG/1052_IWL_ANG_XX. Loading class 1/6: 'ANG', File 345/345: Preprocessed/Train/ANG/1055_TSI_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/374: Preprocessed/Train/DIS/1014_TAI_DIS_XX.wa Loading class 2/6: 'DIS', File 101/374: Preprocessed/Train/DIS/1088_ITH_DIS_XX. Loading class 2/6: 'DIS', File 201/374: Preprocessed/Train/DIS/1063_MTI_DIS_XX. Loading class 2/6: 'DIS', File 301/374: Preprocessed/Train/DIS/1017_TSI_DIS_XX. Loading class 2/6: 'DIS', File 374/374: Preprocessed/Train/DIS/1043_IWW_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/343: Preprocessed/Train/FEA/1012_IEO_FEA_HI.wa Loading class 3/6: 'FEA', File 101/343: Preprocessed/Train/FEA/1014_TIE_FEA_XX. Loading class 3/6: 'FEA', File 201/343: Preprocessed/Train/FEA/1076_MTI_FEA_XX. Loading class 3/6: 'FEA', File 301/343: Preprocessed/Train/FEA/1050_IEO_FEA_LO. Loading class 3/6: 'FEA', File 343/343: Preprocessed/Train/FEA/1088_IEO_FEA_LO.wav.npz                  
 Loading class 4/6: 'HAP', File 1/363: Preprocessed/Train/HAP/1003_TIE_HAP_XX.wa Loading class 4/6: 'HAP', File 101/363: Preprocessed/Train/HAP/1005_IWL_HAP_XX. Loading class 4/6: 'HAP', File 201/363: Preprocessed/Train/HAP/1048_DFA_HAP_XX. Loading class 4/6: 'HAP', File 301/363: Preprocessed/Train/HAP/1019_IEO_HAP_HI. Loading class 4/6: 'HAP', File 363/363: Preprocessed/Train/HAP/1018_ITH_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/328: Preprocessed/Train/NEU/1027_IWW_NEU_XX.wa Loading class 5/6: 'NEU', File 101/328: Preprocessed/Train/NEU/1011_ITH_NEU_XX. Loading class 5/6: 'NEU', File 201/328: Preprocessed/Train/NEU/1047_IEO_NEU_XX. Loading class 5/6: 'NEU', File 301/328: Preprocessed/Train/NEU/1012_IOM_NEU_XX. Loading class 5/6: 'NEU', File 328/328: Preprocessed/Train/NEU/1033_TIE_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/373: Preprocessed/Train/SAD/1014_IOM_SAD_XX.wa Loading class 6/6: 'SAD', File 101/373: Preprocessed/Train/SAD/1073_TSI_SAD_XX. Loading class 6/6: 'SAD', File 201/373: Preprocessed/Train/SAD/1010_TSI_SAD_XX.wav.npz                  
 MyCNN_Keras2: X_shape =  (2048, 96, 420, 1) , channels =  1
Looking for previous weights...
No weights file detected, so starting from scratch.
 Available GPUs =  [] , count =  0
Summary of serial model (duplicated across 0 GPUs):
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input (Conv2D)               (None, 96, 420, 32)       320       
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 48, 210, 32)       0         
_________________________________________________________________
activation_26 (Activation)   (None, 48, 210, 32)       0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 48, 210, 32)       128       
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 48, 210, 32)       9248      
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 24, 105, 32)       0         
_________________________________________________________________
activation_27 (Activation)   (None, 24, 105, 32)       0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 24, 105, 32)       0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 24, 105, 32)       9248      
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 12, 52, 32)        0         
_________________________________________________________________
activation_28 (Activation)   (None, 12, 52, 32)        0         
_________________________________________________________________
dropout_22 (Dropout)         (None, 12, 52, 32)        0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 12, 52, 32)        9248      
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 6, 26, 32)         0         
_________________________________________________________________
activation_29 (Activation)   (None, 6, 26, 32)         0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 6, 26, 32)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 4992)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 128)               639104    
_________________________________________________________________
activation_30 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_24 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 6)                 774       
_________________________________________________________________
Output (Activation)          (None, 6)                 0         
=================================================================
Total params: 668,070
Trainable params: 668,006
Non-trainable params: 64
_________________________________________________________________
Epoch 1/40
2048/2048 [==============================] - 170s 83ms/step - loss: 3.4350 - accuracy: 0.2441

Epoch 00001: saving model to 8Adam0.0001weights.hdf5
Epoch 2/40
2048/2048 [==============================] - 165s 81ms/step - loss: 2.5128 - accuracy: 0.2534

Epoch 00002: saving model to 8Adam0.0001weights.hdf5
Epoch 3/40
2048/2048 [==============================] - 165s 80ms/step - loss: 2.2613 - accuracy: 0.2622

Epoch 00003: saving model to 8Adam0.0001weights.hdf5
Epoch 4/40
2048/2048 [==============================] - 179s 87ms/step - loss: 2.1676 - accuracy: 0.2690

Epoch 00004: saving model to 8Adam0.0001weights.hdf5
Epoch 5/40
2048/2048 [==============================] - 205s 100ms/step - loss: 2.0963 - accuracy: 0.2856

Epoch 00005: saving model to 8Adam0.0001weights.hdf5
Epoch 6/40
2048/2048 [==============================] - 198s 97ms/step - loss: 1.9985 - accuracy: 0.3052

Epoch 00006: saving model to 8Adam0.0001weights.hdf5
Epoch 7/40
2048/2048 [==============================] - 198s 97ms/step - loss: 2.0303 - accuracy: 0.2793

Epoch 00007: saving model to 8Adam0.0001weights.hdf5
Epoch 8/40
2048/2048 [==============================] - 200s 98ms/step - loss: 1.9646 - accuracy: 0.2739

Epoch 00008: saving model to 8Adam0.0001weights.hdf5
Epoch 9/40
2048/2048 [==============================] - 199s 97ms/step - loss: 1.8685 - accuracy: 0.3115

Epoch 00009: saving model to 8Adam0.0001weights.hdf5
Epoch 10/40
2048/2048 [==============================] - 198s 97ms/step - loss: 1.8142 - accuracy: 0.3301

Epoch 00010: saving model to 8Adam0.0001weights.hdf5
Epoch 11/40
2048/2048 [==============================] - 198s 97ms/step - loss: 1.8182 - accuracy: 0.3320

Epoch 00011: saving model to 8Adam0.0001weights.hdf5
Epoch 12/40
2048/2048 [==============================] - 197s 96ms/step - loss: 1.7538 - accuracy: 0.3315

Epoch 00012: saving model to 8Adam0.0001weights.hdf5
Epoch 13/40
2048/2048 [==============================] - 198s 97ms/step - loss: 1.7283 - accuracy: 0.3247

Epoch 00013: saving model to 8Adam0.0001weights.hdf5
Epoch 14/40
2048/2048 [==============================] - 198s 97ms/step - loss: 1.7133 - accuracy: 0.3301

Epoch 00014: saving model to 8Adam0.0001weights.hdf5
Epoch 15/40
2048/2048 [==============================] - 199s 97ms/step - loss: 1.7466 - accuracy: 0.3169

Epoch 00015: saving model to 8Adam0.0001weights.hdf5
Epoch 16/40
2048/2048 [==============================] - 198s 97ms/step - loss: 1.6624 - accuracy: 0.3540

Epoch 00016: saving model to 8Adam0.0001weights.hdf5
Epoch 17/40
2048/2048 [==============================] - 200s 97ms/step - loss: 1.6327 - accuracy: 0.3657

Epoch 00017: saving model to 8Adam0.0001weights.hdf5
Epoch 18/40
2048/2048 [==============================] - 199s 97ms/step - loss: 1.6771 - accuracy: 0.3335

Epoch 00018: saving model to 8Adam0.0001weights.hdf5
Epoch 19/40
2048/2048 [==============================] - 201s 98ms/step - loss: 1.6409 - accuracy: 0.3359

Epoch 00019: saving model to 8Adam0.0001weights.hdf5
Epoch 20/40
2048/2048 [==============================] - 197s 96ms/step - loss: 1.6118 - accuracy: 0.3545

Epoch 00020: saving model to 8Adam0.0001weights.hdf5
Epoch 21/40
2048/2048 [==============================] - 195s 95ms/step - loss: 1.6159 - accuracy: 0.3521

Epoch 00021: saving model to 8Adam0.0001weights.hdf5
Epoch 22/40
2048/2048 [==============================] - 183s 89ms/step - loss: 1.5558 - accuracy: 0.3853

Epoch 00022: saving model to 8Adam0.0001weights.hdf5
Epoch 23/40
2048/2048 [==============================] - 161s 79ms/step - loss: 1.5792 - accuracy: 0.3579

Epoch 00023: saving model to 8Adam0.0001weights.hdf5
Epoch 24/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5957 - accuracy: 0.3535

Epoch 00024: saving model to 8Adam0.0001weights.hdf5
Epoch 25/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5562 - accuracy: 0.3647

Epoch 00025: saving model to 8Adam0.0001weights.hdf5
Epoch 26/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5745 - accuracy: 0.3540

Epoch 00026: saving model to 8Adam0.0001weights.hdf5
Epoch 27/40
2048/2048 [==============================] - 161s 79ms/step - loss: 1.5575 - accuracy: 0.3716

Epoch 00027: saving model to 8Adam0.0001weights.hdf5
Epoch 28/40
2048/2048 [==============================] - 168s 82ms/step - loss: 1.5347 - accuracy: 0.3867

Epoch 00028: saving model to 8Adam0.0001weights.hdf5
Epoch 29/40
2048/2048 [==============================] - 168s 82ms/step - loss: 1.5560 - accuracy: 0.3691

Epoch 00029: saving model to 8Adam0.0001weights.hdf5
Epoch 30/40
2048/2048 [==============================] - 164s 80ms/step - loss: 1.5284 - accuracy: 0.4023

Epoch 00030: saving model to 8Adam0.0001weights.hdf5
Epoch 31/40
2048/2048 [==============================] - 162s 79ms/step - loss: 1.5242 - accuracy: 0.3789

Epoch 00031: saving model to 8Adam0.0001weights.hdf5
Epoch 32/40
2048/2048 [==============================] - 162s 79ms/step - loss: 1.5348 - accuracy: 0.3804

Epoch 00032: saving model to 8Adam0.0001weights.hdf5
Epoch 33/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5261 - accuracy: 0.3667

Epoch 00033: saving model to 8Adam0.0001weights.hdf5
Epoch 34/40
2048/2048 [==============================] - 161s 78ms/step - loss: 1.5162 - accuracy: 0.3955

Epoch 00034: saving model to 8Adam0.0001weights.hdf5
Epoch 35/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5061 - accuracy: 0.3960

Epoch 00035: saving model to 8Adam0.0001weights.hdf5
Epoch 36/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.5181 - accuracy: 0.3872

Epoch 00036: saving model to 8Adam0.0001weights.hdf5
Epoch 37/40
2048/2048 [==============================] - 160s 78ms/step - loss: 1.4902 - accuracy: 0.4014

Epoch 00037: saving model to 8Adam0.0001weights.hdf5
Epoch 38/40
2048/2048 [==============================] - 163s 79ms/step - loss: 1.4853 - accuracy: 0.4141

Epoch 00038: saving model to 8Adam0.0001weights.hdf5
Epoch 39/40
2048/2048 [==============================] - 164s 80ms/step - loss: 1.5134 - accuracy: 0.3979

Epoch 00039: saving model to 8Adam0.0001weights.hdf5
Epoch 40/40
2048/2048 [==============================] - 164s 80ms/step - loss: 1.4538 - accuracy: 0.4160

Epoch 00040: saving model to 8Adam0.0001weights.hdf5
class_names =  ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']
       total files =  266 , going to load total_load =  266
total files =  266 , going to load total_load =  266
   get_sample_dimensions: 1075_IEO_ANG_HI.wav.npz: melgram.shape =  (1, 96, 420, 1)
 melgram dimensions:  (1, 96, 420, 1)

 Loading class 1/6: 'ANG', File 1/44: Preprocessed/Train/../Dev/ANG/1064_IWW_ANG Loading class 1/6: 'ANG', File 44/44: Preprocessed/Train/../Dev/ANG/1085_IWW_ANG_XX.wav.npz                  
 Loading class 2/6: 'DIS', File 1/42: Preprocessed/Train/../Dev/DIS/1062_IEO_DIS Loading class 2/6: 'DIS', File 42/42: Preprocessed/Train/../Dev/DIS/1058_TAI_DIS_XX.wav.npz                  
 Loading class 3/6: 'FEA', File 1/62: Preprocessed/Train/../Dev/FEA/1059_ITS_FEA Loading class 3/6: 'FEA', File 62/62: Preprocessed/Train/../Dev/FEA/1043_DFA_FEA_XX.wav.npz                  
 Loading class 4/6: 'HAP', File 1/47: Preprocessed/Train/../Dev/HAP/1022_IWW_HAP Loading class 4/6: 'HAP', File 47/47: Preprocessed/Train/../Dev/HAP/1087_TAI_HAP_XX.wav.npz                  
 Loading class 5/6: 'NEU', File 1/31: Preprocessed/Train/../Dev/NEU/1075_DFA_NEU Loading class 5/6: 'NEU', File 31/31: Preprocessed/Train/../Dev/NEU/1067_ITH_NEU_XX.wav.npz                  
 Loading class 6/6: 'SAD', File 1/40: Preprocessed/Train/../Dev/SAD/1077_MTI_SAD Loading class 6/6: 'SAD', File 40/40: Preprocessed/Train/../Dev/SAD/1037_IEO_SAD_LO.wav.npz                  
Adam  gives the following results:
Dev set loss: 1.7126594790838714
Dev set accuracy: 0.25563910603523254
(tensorflow) Evangelie-2:panotti evangelie$ 
